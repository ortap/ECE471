{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Midterm - Adam with AG_News_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LkhSl6NpC1zL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Midterm - AG News Data classification with Adam\n",
        "### Shailesh Patro\n",
        "\n",
        "I have implemented an Adam optimizer based on *ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION* by Diederik P. Kingma & Jimmy Lei Ba         \n",
        "(https://arxiv.org/pdf/1412.6980v8.pdf). \n",
        "The implementation uses Keras base class and common methods for compatbility with a keras model. The keras compatibility is preferable for testing the optimizer quickly on several datasets.\n",
        "\n",
        "I have tested the optimizer on three data sets:\n",
        "\n",
        "1.   Sine Curve Regression\n",
        "2.   MNIST Classification\n",
        "3.   AG News data Classification\n",
        "\n",
        "\n",
        "While doing this assignment, I used the tutorial presented here: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/. The model presented in this tutorial uses word embeddings which is superior to the bag of words model."
      ]
    },
    {
      "metadata": {
        "id": "abkaxuFoufGf",
        "colab_type": "code",
        "outputId": "49b7022b-55b7-46dd-a846-a99838ff72af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QiuGzC-Arzcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, BatchNormalization, Activation,Flatten\n",
        "from keras.layers import Embedding, Input, Dense, Dropout, Lambda, MaxPooling1D\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.optimizers import Optimizer\n",
        "\n",
        "\n",
        "dataPath = '/content/gdrive/My Drive/Colab Notebooks/ag_news_csv/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flOqgRRrEKWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(dataPath+'train.csv', names=[\"label\", \"title\", \"text\"])\n",
        "test = pd.read_csv(dataPath+'test.csv', names=[\"label\",\"title\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1YD4HY4ewFc",
        "colab_type": "code",
        "outputId": "7d8365c1-c09b-4ce6-d509-14abd1ddaf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = train[\"title\"] + \" \" + train[\"text\"]\n",
        "y_train = train[\"label\"]\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
        "x_train\n",
        "# y_train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54257     Pakistanis ban religious meetings Authorities ...\n",
              "57940     Marks  amp; Spencer Says First-Half Earnings F...\n",
              "19952     SFA DELAY MOLDOVA DECISION The Scottish Footba...\n",
              "9864      Deutsche Bank hit again by phishing attack Aft...\n",
              "116957    Top British Official Resigns Amid Scandal A ca...\n",
              "8612      Japan to Deport Ex-Chess Champion Bobby Fische...\n",
              "48105     Moats sinks Fresno St. RUSTON, La. -- Ryan Moa...\n",
              "13701     40 injured in French motorway pileup Bordeaux,...\n",
              "29994     Afghan President Escapes Attack Afghanistan Pr...\n",
              "38872     Roddick Powers U.S. to Lead in Davis Semis CHA...\n",
              "62115     Walsh in charge for Masconomet Myles Walsh sto...\n",
              "92763     Wholesale prices jump in October by 1.7 percen...\n",
              "3707      Sprint stars create new Greek tragedy ATHENS, ...\n",
              "10502     Server sales rocket by almost a quarter HP and...\n",
              "52501     Ethics Panel Rebukes DeLay Twice in a Week WAS...\n",
              "106083    Barrera Proved he #39;s Better than Morales Th...\n",
              "98416     Alien aims to multiply and thrive MORGAN HILL,...\n",
              "108781    Riggs Bank Replaces Its Chief Legal Officer Ri...\n",
              "119364    Report: Bertuzzi Near Plea Bargain  VANCOUVER ...\n",
              "73664     Xandros rolls out Linux desktop management app...\n",
              "51579     Congress Speeds Up 9/11 Legislation Vote WASHI...\n",
              "95463     NHL Draft Will Wait on New Contract (AP) AP - ...\n",
              "105286    Lebanon march for Syrians to stay Large number...\n",
              "105320    Iraqi police, troops under insurgent fire Iraq...\n",
              "10452     Supporters of Sistani Fired Upon, 20 Dead: Wit...\n",
              "13068     Pope returns rare icon to Russia A Vatican car...\n",
              "44925     IBM claims most powerful supercomputer crown I...\n",
              "106672    Russia offers strategic partnership to India N...\n",
              "16618     Edwards Promises to Spread U.S. Wealth (AP) AP...\n",
              "32874     FTC in Settlement With Company That Promoted A...\n",
              "                                ...                        \n",
              "45507     Asian Elephants Threatened by Poachers, Wester...\n",
              "116535    IBM #39;s PC deal seen as strategic withdrawal...\n",
              "73521     Musharrafs new floater leaks, badly PAKISTANI ...\n",
              "83012     A Look at U.S. Military Deaths in Iraq (AP) AP...\n",
              "14944     Schiavone Starts Off Open With Victory (AP) AP...\n",
              "96676     Torres Chosen First in MLS Expansion Draft (AP...\n",
              "68861     Abu Ghraib and Guantanamo absent from US presi...\n",
              "35662     ConAgra Profit Falls as Prices Rise  CHICAGO (...\n",
              "17747     Microsoft: Linux may mean price cuts, fewer sa...\n",
              "101785    Olowokandi misses game after being arrested at...\n",
              "65647     The worst sides of two nations on display The ...\n",
              "33710     Hong Kong Emerge as Dominant Force in Fencing ...\n",
              "71200     Lions keep roaring on road EAST RUTHERFORD, NJ...\n",
              "118857    Hope and risk in Middle East The recent rhetor...\n",
              "118831    Announcers cross-checked by NHL lockout Someda...\n",
              "23166     Sindelar takes early lead with 5-under 66 at r...\n",
              "55409     Howard wins fourth term in Australian election...\n",
              "65632     Indonesian Ex-General Sworn in as President (R...\n",
              "22241     EBay at a Crossroads: Can Buy Now' Share Space...\n",
              "89302     Bush and Blair present united front on new cha...\n",
              "46203     Microsoft Tells Judge of Harm in Changing Wind...\n",
              "73299     Update 13: Oil Prices Little Changed on Norway...\n",
              "15377     US tech execs more optimistic about spending: ...\n",
              "63206     Lions report We were unable to get off the fie...\n",
              "119906    Jones gets to give knockout analysis It won #3...\n",
              "61404     New Google Tool Expands on Core Technology Goo...\n",
              "17730     UN Security Council Tries to Stop Syrian Meddl...\n",
              "28030     Anwar Ibrahim to seek royal pardon Malaysia #3...\n",
              "15725     WTO rules for EU in US trade row The World Tra...\n",
              "118270    Motorola in 3-year contract extension with Nex...\n",
              "Length: 108000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "uoTQJaeZlNor",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = test[\"title\"] + \" \" + test[\"text\"]\n",
        "y_test = test[\"label\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOaSdSU2yGDG",
        "colab_type": "code",
        "outputId": "8880495b-f5f0-4722-c9eb-6a45c13ae001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "num_class = 4\n",
        "vocab = 50000 # size of vocabulary\n",
        "max_length = 1024\n",
        "\n",
        "encode_train = [one_hot(d,vocab) for d in x_train]\n",
        "encode_val = [one_hot(d,vocab) for d in x_val]\n",
        "encode_test = [one_hot(d,vocab) for d in x_test]\n",
        "pad_train = np.array(pad_sequences(encode_train, maxlen=max_length, padding='post'))\n",
        "pad_val = np.array(pad_sequences(encode_val, maxlen=max_length, padding='post'))\n",
        "pad_test = np.array(pad_sequences(encode_test, maxlen=max_length, padding='post'))\n",
        "trainLen = pad_train.shape[0]\n",
        "valLen = pad_val.shape[0]\n",
        "testLen = pad_test.shape[0]\n",
        "pad_train = pad_train.flatten()\n",
        "pad_val = pad_val.flatten()\n",
        "pad_test = pad_test.flatten()\n",
        "\n",
        "pad_train = pad_train.reshape(trainLen,max_length)\n",
        "pad_val = pad_val.reshape(valLen,max_length)\n",
        "pad_test = pad_test.reshape(testLen,max_length)\n",
        "\n",
        "y_train[y_train==4] = 0\n",
        "y_val[y_val==4] = 0\n",
        "y_test[y_test==4] = 0\n",
        "y_train = keras.utils.to_categorical(y_train, num_class)\n",
        "y_val = keras.utils.to_categorical(y_val, num_class)\n",
        "y_test = keras.utils.to_categorical(y_test, num_class)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XK0uapVX8og6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdamOptimizer(Optimizer):\n",
        "  def __init__(self, alpha=0.001, beta_1=0.9,\n",
        "               beta_2=0.999, epsilon=1e-08, \n",
        "               **kwargs):\n",
        "    super(AdamOptimizer, self).__init__(**kwargs)\n",
        "    with keras.backend.name_scope(self.__class__.__name__):\n",
        "      self.iterations = keras.backend.variable(0, dtype='int64', name='iterations')\n",
        "      # alpha is the stepsize/learning rate as described in the paper\n",
        "      self.alpha = keras.backend.variable(alpha, name='alpha')\n",
        "      # beta_1, beta_2 are the exponential decay rates for the moment estimates\n",
        "      self.beta_1 = keras.backend.variable(beta_1, name='beta_1')\n",
        "      self.beta_2 = keras.backend.variable(beta_2, name='beta_2')\n",
        "      self.epsilon = epsilon\n",
        " \n",
        "\n",
        "\n",
        "  def get_updates(self, loss, params):\n",
        "    xs = params\n",
        "    # get gradients with tensorflow's built in gradient function\n",
        "    grads = tf.gradients(loss, xs, colocate_gradients_with_ops=True)\n",
        "    self.updates = [tf.assign_add(self.iterations, 1)]\n",
        "    # alpha is the learning rate as defined in the paper\n",
        "    alpha = self.alpha\n",
        "    # increment timestep by 1\n",
        "    t = tf.cast(self.iterations, 'float32') + 1\n",
        "    \n",
        "    # suggested improvement as mentioned in section 2: algorithm\n",
        "    alpha_t = alpha * (tf.sqrt(1. - tf.pow(self.beta_2, t)) / (1. - tf.pow(self.beta_1, t))) \n",
        "    \n",
        "    # initialize m, v to zero\n",
        "    ms = [keras.backend.zeros(x.shape, dtype=x.dtype.base_dtype.name) for x in xs]\n",
        "    vs = [keras.backend.zeros(x.shape, dtype=x.dtype.base_dtype.name) for x in xs]\n",
        " \n",
        "    self.weights = [self.iterations] + ms + vs\n",
        "    \n",
        "    for x, g, m, v in zip(xs, grads, ms, vs):\n",
        "        # Update biased first moment estimate\n",
        "        m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "        \n",
        "        # Update biased second raw moment estimate \n",
        "        # also used tensorflow's elementwise square\n",
        "        v_t = (self.beta_2 * v) + (1. - self.beta_2) * tf.square(g) \n",
        "        \n",
        "        # Update Parameters\n",
        "        x_t = x - alpha_t * m_t / (tf.sqrt(v_t) + self.epsilon)\n",
        "        self.updates.append(tf.assign(m, m_t))\n",
        "        self.updates.append(tf.assign(v, v_t))\n",
        "        new_x = x_t\n",
        "\n",
        "        self.updates.append(tf.assign(x, new_x))\n",
        "    return self.updates\n",
        "\n",
        "  \n",
        "  \n",
        "  def get_config(self):\n",
        "    config = {'alpha': float(keras.backend.get_value(self.alpha)),\n",
        "              'beta_1': float(keras.backend.get_value(self.beta_1)),\n",
        "              'beta_2': float(keras.backend.get_value(self.beta_2)),\n",
        "              'epsilon': self.epsilon}\n",
        "    base_config = super(AdamOptimizer, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "  \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSJklMEOoKIx",
        "colab_type": "code",
        "outputId": "6ff525aa-df33-45cc-f18c-78f9a58ac677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab, 512, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "adamopt = AdamOptimizer()\n",
        "model.compile(optimizer=adamopt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(pad_train,y_train, epochs=4, batch_size=1024,\n",
        "    validation_data=(pad_val,y_val), verbose=1)\n",
        "\n",
        "scores = model.evaluate(pad_test,y_test)\n",
        "print('Test loss: ', scores[0])\n",
        "print('Test accuracy:',scores[1])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1024, 512)         25600000  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 524288)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2097156   \n",
            "=================================================================\n",
            "Total params: 27,697,156\n",
            "Trainable params: 27,697,156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 108000 samples, validate on 12000 samples\n",
            "Epoch 1/4\n",
            "108000/108000 [==============================] - 34s 316us/step - loss: 4.7368 - acc: 0.5247 - val_loss: 0.3456 - val_acc: 0.9001\n",
            "Epoch 2/4\n",
            "108000/108000 [==============================] - 33s 301us/step - loss: 0.2263 - acc: 0.9315 - val_loss: 0.2575 - val_acc: 0.9136\n",
            "Epoch 3/4\n",
            "108000/108000 [==============================] - 32s 301us/step - loss: 0.1284 - acc: 0.9624 - val_loss: 0.2565 - val_acc: 0.9147\n",
            "Epoch 4/4\n",
            "108000/108000 [==============================] - 32s 301us/step - loss: 0.0718 - acc: 0.9817 - val_loss: 0.2683 - val_acc: 0.9128\n",
            "7600/7600 [==============================] - 1s 161us/step\n",
            "Test loss:  0.2705410565788809\n",
            "Test accuracy: 0.9125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mjsKab2KJn4A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "embedding_4 (Embedding)      (None, 1024, 512)         25600000  \n",
        "_________________________________________________________________\n",
        "flatten_4 (Flatten)          (None, 524288)            0         \n",
        "_________________________________________________________________\n",
        "dense_4 (Dense)              (None, 4)                 2097156   \n",
        "=================================================================\n",
        "Total params: 27,697,156\n",
        "Trainable params: 27,697,156\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n",
        "7600/7600 [==============================] - 1s 181us/step\n",
        "Test loss:  0.26758113999900063\n",
        "Test accuracy: 0.9169736842105263"
      ]
    }
  ]
}