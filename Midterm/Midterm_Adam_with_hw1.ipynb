{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Midterm - Adam with hw1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow]",
      "language": "python",
      "name": "conda-env-tensorflow-py"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1UQ_RarO1uT5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Midterm - Adam with HW1 - Sine curve regression\n",
        "### Shailesh Patro\n",
        "\n",
        "I have implemented an Adam optimizer based on *ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION* by Diederik P. Kingma & Jimmy Lei Ba         \n",
        "(https://arxiv.org/pdf/1412.6980v8.pdf). \n",
        "The implementation uses Keras base class and common methods for compatbility with a keras model. The keras compatibility is preferable for testing the optimizer quickly on several datasets.\n",
        "\n",
        "I have tested the optimizer on three data sets:\n",
        "\n",
        "1.   Sine Curve Regression\n",
        "2.   MNIST Classification\n",
        "3.   AG News data Classification\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zM29gtMn3cXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7438f26-cbfa-4754-a414-55a45ca3d636"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, BatchNormalization, Activation,Flatten\n",
        "from keras.layers import Embedding, Input, Dense, Dropout, Lambda, MaxPooling1D\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.optimizers import Optimizer\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8_k3Gvi-pi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdamOptimizer(Optimizer):\n",
        "  def __init__(self, alpha=0.001, beta_1=0.9,\n",
        "               beta_2=0.999, epsilon=1e-08, \n",
        "               **kwargs):\n",
        "    super(AdamOptimizer, self).__init__(**kwargs)\n",
        "    with keras.backend.name_scope(self.__class__.__name__):\n",
        "      self.iterations = keras.backend.variable(0, dtype='int64', name='iterations')\n",
        "      # alpha is the stepsize/learning rate as described in the paper\n",
        "      self.alpha = keras.backend.variable(alpha, name='alpha')\n",
        "      # beta_1, beta_2 are the exponential decay rates for the moment estimates\n",
        "      self.beta_1 = keras.backend.variable(beta_1, name='beta_1')\n",
        "      self.beta_2 = keras.backend.variable(beta_2, name='beta_2')\n",
        "      self.epsilon = epsilon\n",
        " \n",
        "\n",
        "\n",
        "  def get_updates(self, loss, params):\n",
        "    xs = params\n",
        "    # get gradients with tensorflow's built in gradient function\n",
        "    grads = tf.gradients(loss, xs, colocate_gradients_with_ops=True)\n",
        "    self.updates = [tf.assign_add(self.iterations, 1)]\n",
        "    # alpha is the learning rate as defined in the paper\n",
        "    alpha = self.alpha\n",
        "    # increment timestep by 1\n",
        "    t = tf.cast(self.iterations, 'float32') + 1\n",
        "    \n",
        "    # suggested improvement as mentioned in section 2: algorithm\n",
        "    alpha_t = alpha * (tf.sqrt(1. - tf.pow(self.beta_2, t)) / (1. - tf.pow(self.beta_1, t))) \n",
        "    \n",
        "    # initialize m, v to zero\n",
        "    ms = [keras.backend.zeros(x.shape, dtype=x.dtype.base_dtype.name) for x in xs]\n",
        "    vs = [keras.backend.zeros(x.shape, dtype=x.dtype.base_dtype.name) for x in xs]\n",
        " \n",
        "    self.weights = [self.iterations] + ms + vs\n",
        "    \n",
        "    for x, g, m, v in zip(xs, grads, ms, vs):\n",
        "        # Update biased first moment estimate\n",
        "        m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "        \n",
        "        # Update biased second raw moment estimate \n",
        "        # also used tensorflow's elementwise square\n",
        "        v_t = (self.beta_2 * v) + (1. - self.beta_2) * tf.square(g) \n",
        "        \n",
        "        # Update Parameters\n",
        "        x_t = x - alpha_t * m_t / (tf.sqrt(v_t) + self.epsilon)\n",
        "        self.updates.append(tf.assign(m, m_t))\n",
        "        self.updates.append(tf.assign(v, v_t))\n",
        "        new_x = x_t\n",
        "\n",
        "        self.updates.append(tf.assign(x, new_x))\n",
        "    return self.updates\n",
        "\n",
        "  \n",
        "  \n",
        "  def get_config(self):\n",
        "    config = {'alpha': float(keras.backend.get_value(self.alpha)),\n",
        "              'beta_1': float(keras.backend.get_value(self.beta_1)),\n",
        "              'beta_2': float(keras.backend.get_value(self.beta_2)),\n",
        "              'epsilon': self.epsilon}\n",
        "    base_config = super(AdamOptimizer, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDGqHbRr1uUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34034
        },
        "outputId": "705e9606-6c5b-4b8e-89d9-9992f85b4180"
      },
      "cell_type": "code",
      "source": [
        "## list inputs\n",
        "\n",
        "N = 100 # Sample size\n",
        "# M = 6 # number of gaussian basis functions\n",
        "# iteration = 1000 # else recognized as number of batches\n",
        "# learning_rate = 0.01 # the eta in newton's method\n",
        "sigma = 0.1 # noise in data\n",
        "\n",
        "## sample data points from a sine wave \n",
        "x_vals = np.random.uniform(0.0, 1.0, N) # A sort may make this easy to graph this later\n",
        "y_vals = np.sin(np.pi*2*x_vals) + np.random.normal(0, sigma, N) # noisy\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(40, activation='tanh', input_shape=(1,)))\n",
        "model.add(Dense(12, activation = 'tanh'))\n",
        "model.add(Dense(1, activation = 'tanh'))\n",
        "adamopt = AdamOptimizer()\n",
        "model.compile(optimizer=adamopt, loss='mse', metrics = ['mean_squared_error'])\n",
        "model.fit(x_vals,y_vals, epochs=1000, batch_size=8, verbose=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.4686 - mean_squared_error: 0.4686\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.4218 - mean_squared_error: 0.4218\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.3832 - mean_squared_error: 0.3832\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.3474 - mean_squared_error: 0.3474\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.3148 - mean_squared_error: 0.3148\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.2830 - mean_squared_error: 0.2830\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.2600 - mean_squared_error: 0.2600\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.2374 - mean_squared_error: 0.2374\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.2186 - mean_squared_error: 0.2186\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.2032 - mean_squared_error: 0.2032\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1886 - mean_squared_error: 0.1886\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.1774 - mean_squared_error: 0.1774\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1691 - mean_squared_error: 0.1691\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1602 - mean_squared_error: 0.1602\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.1526 - mean_squared_error: 0.1526\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1471 - mean_squared_error: 0.1471\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1425 - mean_squared_error: 0.1425\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.1368 - mean_squared_error: 0.1368\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1342 - mean_squared_error: 0.1342\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1341 - mean_squared_error: 0.1341\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.1306 - mean_squared_error: 0.1306\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1262 - mean_squared_error: 0.1262\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1228 - mean_squared_error: 0.1228\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1208 - mean_squared_error: 0.1208\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.1191 - mean_squared_error: 0.1191\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1182 - mean_squared_error: 0.1182\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1166 - mean_squared_error: 0.1166\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1160 - mean_squared_error: 0.1160\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1150 - mean_squared_error: 0.1150\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1144 - mean_squared_error: 0.1144\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.1139 - mean_squared_error: 0.1139\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1135 - mean_squared_error: 0.1135\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.1126 - mean_squared_error: 0.1126\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1125 - mean_squared_error: 0.1125\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.1125 - mean_squared_error: 0.1125\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1119 - mean_squared_error: 0.1119\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.1118 - mean_squared_error: 0.1118\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1123 - mean_squared_error: 0.1123\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1113 - mean_squared_error: 0.1113\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1113 - mean_squared_error: 0.1113\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1111 - mean_squared_error: 0.1111\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1109 - mean_squared_error: 0.1109\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1114 - mean_squared_error: 0.1114\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1118 - mean_squared_error: 0.1118\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.1113 - mean_squared_error: 0.1113\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1121 - mean_squared_error: 0.1121\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1112 - mean_squared_error: 0.1112\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1124 - mean_squared_error: 0.1124\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1111 - mean_squared_error: 0.1111\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.1111 - mean_squared_error: 0.1111\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1111 - mean_squared_error: 0.1111\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1112 - mean_squared_error: 0.1112\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1115 - mean_squared_error: 0.1115\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1111 - mean_squared_error: 0.1111\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1112 - mean_squared_error: 0.1112\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1115 - mean_squared_error: 0.1115\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1119 - mean_squared_error: 0.1119\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1109 - mean_squared_error: 0.1109\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1115 - mean_squared_error: 0.1115\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 0s 202us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1109 - mean_squared_error: 0.1109\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1107 - mean_squared_error: 0.1107\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1114 - mean_squared_error: 0.1114\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1109 - mean_squared_error: 0.1109\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1101 - mean_squared_error: 0.1101\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1098 - mean_squared_error: 0.1098\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1110 - mean_squared_error: 0.1110\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1103 - mean_squared_error: 0.1103\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1097 - mean_squared_error: 0.1097\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1105 - mean_squared_error: 0.1105\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.1097 - mean_squared_error: 0.1097\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1097 - mean_squared_error: 0.1097\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.1097 - mean_squared_error: 0.1097\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1094 - mean_squared_error: 0.1094\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1097 - mean_squared_error: 0.1097\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1106 - mean_squared_error: 0.1106\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1098 - mean_squared_error: 0.1098\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1098 - mean_squared_error: 0.1098\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1095 - mean_squared_error: 0.1095\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1093 - mean_squared_error: 0.1093\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1094 - mean_squared_error: 0.1094\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.1092 - mean_squared_error: 0.1092\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1092 - mean_squared_error: 0.1092\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.1092 - mean_squared_error: 0.1092\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1095 - mean_squared_error: 0.1095\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1102 - mean_squared_error: 0.1102\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1093 - mean_squared_error: 0.1093\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1091 - mean_squared_error: 0.1091\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1108 - mean_squared_error: 0.1108\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1091 - mean_squared_error: 0.1091\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1089 - mean_squared_error: 0.1089\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.1089 - mean_squared_error: 0.1089\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1092 - mean_squared_error: 0.1092\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1090 - mean_squared_error: 0.1090\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1089 - mean_squared_error: 0.1089\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.1089 - mean_squared_error: 0.1089\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.1092 - mean_squared_error: 0.1092\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1087 - mean_squared_error: 0.1087\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1086 - mean_squared_error: 0.1086\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1085 - mean_squared_error: 0.1085\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1088 - mean_squared_error: 0.1088\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1096 - mean_squared_error: 0.1096\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.1104 - mean_squared_error: 0.1104\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.1089 - mean_squared_error: 0.1089\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1085 - mean_squared_error: 0.1085\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.1090 - mean_squared_error: 0.1090\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1086 - mean_squared_error: 0.1086\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1082 - mean_squared_error: 0.1082\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.1086 - mean_squared_error: 0.1086\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.1093 - mean_squared_error: 0.1093\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1082 - mean_squared_error: 0.1082\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.1077 - mean_squared_error: 0.1077\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.1079 - mean_squared_error: 0.1079\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.1076 - mean_squared_error: 0.1076\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1076 - mean_squared_error: 0.1076\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.1073 - mean_squared_error: 0.1073\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.1076 - mean_squared_error: 0.1076\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.1100 - mean_squared_error: 0.1100\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.1111 - mean_squared_error: 0.1111\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1082 - mean_squared_error: 0.1082\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.1073 - mean_squared_error: 0.1073\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.1067 - mean_squared_error: 0.1067\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.1069 - mean_squared_error: 0.1069\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 0s 192us/step - loss: 0.1064 - mean_squared_error: 0.1064\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1064 - mean_squared_error: 0.1064\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.1061 - mean_squared_error: 0.1061\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.1056 - mean_squared_error: 0.1056\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.1050 - mean_squared_error: 0.1050\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.1047 - mean_squared_error: 0.1047\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1045 - mean_squared_error: 0.1045\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1042 - mean_squared_error: 0.1042\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1045 - mean_squared_error: 0.1045\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1041 - mean_squared_error: 0.1041\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1033 - mean_squared_error: 0.1033\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.1032 - mean_squared_error: 0.1032\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.1022 - mean_squared_error: 0.1022\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.1013 - mean_squared_error: 0.1013\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.1006 - mean_squared_error: 0.1006\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.1004 - mean_squared_error: 0.1004\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.0997 - mean_squared_error: 0.0997\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0987 - mean_squared_error: 0.0987\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0979 - mean_squared_error: 0.0979\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0973 - mean_squared_error: 0.0973\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0974 - mean_squared_error: 0.0974\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0954 - mean_squared_error: 0.0954\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0943 - mean_squared_error: 0.0943\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0936 - mean_squared_error: 0.0936\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0923 - mean_squared_error: 0.0923\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0915 - mean_squared_error: 0.0915\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0924 - mean_squared_error: 0.0924\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0893 - mean_squared_error: 0.0893\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0873 - mean_squared_error: 0.0873\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.0862 - mean_squared_error: 0.0862\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0843 - mean_squared_error: 0.0843\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0791 - mean_squared_error: 0.0791\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0760 - mean_squared_error: 0.0760\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0733 - mean_squared_error: 0.0733\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0704 - mean_squared_error: 0.0704\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0699 - mean_squared_error: 0.0699\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.0667 - mean_squared_error: 0.0667\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.0628 - mean_squared_error: 0.0628\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0605 - mean_squared_error: 0.0605\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0586 - mean_squared_error: 0.0586\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0569 - mean_squared_error: 0.0569\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0552 - mean_squared_error: 0.0552\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0538 - mean_squared_error: 0.0538\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0522 - mean_squared_error: 0.0522\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0511 - mean_squared_error: 0.0511\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0501 - mean_squared_error: 0.0501\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0492 - mean_squared_error: 0.0492\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0476 - mean_squared_error: 0.0476\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0471 - mean_squared_error: 0.0471\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0459 - mean_squared_error: 0.0459\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0463 - mean_squared_error: 0.0463\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0453 - mean_squared_error: 0.0453\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0438 - mean_squared_error: 0.0438\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0445 - mean_squared_error: 0.0445\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0438 - mean_squared_error: 0.0438\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0427 - mean_squared_error: 0.0427\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 0s 201us/step - loss: 0.0430 - mean_squared_error: 0.0430\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0416 - mean_squared_error: 0.0416\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0428 - mean_squared_error: 0.0428\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0415 - mean_squared_error: 0.0415\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0425 - mean_squared_error: 0.0425\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0411 - mean_squared_error: 0.0411\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0405 - mean_squared_error: 0.0405\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0402 - mean_squared_error: 0.0402\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0398 - mean_squared_error: 0.0398\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
            "Epoch 382/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0408 - mean_squared_error: 0.0408\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0400 - mean_squared_error: 0.0400\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0389 - mean_squared_error: 0.0389\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0384 - mean_squared_error: 0.0384\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0375 - mean_squared_error: 0.0375\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0374 - mean_squared_error: 0.0374\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0339 - mean_squared_error: 0.0339\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 0s 279us/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
            "Epoch 417/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0332 - mean_squared_error: 0.0332\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
            "Epoch 428/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
            "Epoch 429/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
            "Epoch 430/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
            "Epoch 431/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
            "Epoch 432/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
            "Epoch 433/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
            "Epoch 434/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
            "Epoch 435/1000\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
            "Epoch 436/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
            "Epoch 437/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
            "Epoch 438/1000\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
            "Epoch 439/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
            "Epoch 440/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
            "Epoch 441/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
            "Epoch 442/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
            "Epoch 443/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
            "Epoch 444/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
            "Epoch 445/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
            "Epoch 446/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0304 - mean_squared_error: 0.0304\n",
            "Epoch 447/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
            "Epoch 448/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0298 - mean_squared_error: 0.0298\n",
            "Epoch 449/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
            "Epoch 450/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
            "Epoch 451/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
            "Epoch 452/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
            "Epoch 453/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
            "Epoch 454/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0293 - mean_squared_error: 0.0293\n",
            "Epoch 455/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0299 - mean_squared_error: 0.0299\n",
            "Epoch 456/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0296 - mean_squared_error: 0.0296\n",
            "Epoch 457/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0296 - mean_squared_error: 0.0296\n",
            "Epoch 458/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
            "Epoch 459/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
            "Epoch 460/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
            "Epoch 461/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
            "Epoch 462/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
            "Epoch 463/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0288 - mean_squared_error: 0.0288\n",
            "Epoch 464/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0292 - mean_squared_error: 0.0292\n",
            "Epoch 465/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
            "Epoch 466/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
            "Epoch 467/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0285 - mean_squared_error: 0.0285\n",
            "Epoch 468/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0282 - mean_squared_error: 0.0282\n",
            "Epoch 469/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
            "Epoch 470/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
            "Epoch 471/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
            "Epoch 472/1000\n",
            "100/100 [==============================] - 0s 201us/step - loss: 0.0277 - mean_squared_error: 0.0277\n",
            "Epoch 473/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0283 - mean_squared_error: 0.0283\n",
            "Epoch 474/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
            "Epoch 475/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
            "Epoch 476/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
            "Epoch 477/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0276 - mean_squared_error: 0.0276\n",
            "Epoch 478/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
            "Epoch 479/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
            "Epoch 480/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0279 - mean_squared_error: 0.0279\n",
            "Epoch 481/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
            "Epoch 482/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
            "Epoch 483/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
            "Epoch 484/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
            "Epoch 485/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0268 - mean_squared_error: 0.0268\n",
            "Epoch 486/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
            "Epoch 487/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
            "Epoch 488/1000\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
            "Epoch 489/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
            "Epoch 490/1000\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0268 - mean_squared_error: 0.0268\n",
            "Epoch 491/1000\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
            "Epoch 492/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
            "Epoch 493/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
            "Epoch 494/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
            "Epoch 495/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
            "Epoch 496/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
            "Epoch 497/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
            "Epoch 498/1000\n",
            "100/100 [==============================] - 0s 197us/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
            "Epoch 499/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
            "Epoch 500/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
            "Epoch 501/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
            "Epoch 502/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
            "Epoch 503/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
            "Epoch 504/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
            "Epoch 505/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
            "Epoch 506/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
            "Epoch 507/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
            "Epoch 508/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
            "Epoch 509/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0262 - mean_squared_error: 0.0262\n",
            "Epoch 510/1000\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
            "Epoch 511/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
            "Epoch 512/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0247 - mean_squared_error: 0.0247\n",
            "Epoch 513/1000\n",
            "100/100 [==============================] - 0s 285us/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
            "Epoch 514/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
            "Epoch 515/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
            "Epoch 516/1000\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
            "Epoch 517/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
            "Epoch 518/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
            "Epoch 519/1000\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
            "Epoch 520/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
            "Epoch 521/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
            "Epoch 522/1000\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
            "Epoch 523/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
            "Epoch 524/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
            "Epoch 525/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
            "Epoch 526/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
            "Epoch 527/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
            "Epoch 528/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
            "Epoch 529/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
            "Epoch 530/1000\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
            "Epoch 531/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
            "Epoch 532/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
            "Epoch 533/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0234 - mean_squared_error: 0.0234\n",
            "Epoch 534/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
            "Epoch 535/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
            "Epoch 536/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
            "Epoch 537/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0234 - mean_squared_error: 0.0234\n",
            "Epoch 538/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
            "Epoch 539/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
            "Epoch 540/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
            "Epoch 541/1000\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
            "Epoch 542/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
            "Epoch 543/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0234 - mean_squared_error: 0.0234\n",
            "Epoch 544/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
            "Epoch 545/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0225 - mean_squared_error: 0.0225\n",
            "Epoch 546/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
            "Epoch 547/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
            "Epoch 548/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0224 - mean_squared_error: 0.0224\n",
            "Epoch 549/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 550/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
            "Epoch 551/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 552/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
            "Epoch 553/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
            "Epoch 554/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 555/1000\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
            "Epoch 556/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
            "Epoch 557/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0221 - mean_squared_error: 0.0221\n",
            "Epoch 558/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
            "Epoch 559/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
            "Epoch 560/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
            "Epoch 561/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
            "Epoch 562/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0216 - mean_squared_error: 0.0216\n",
            "Epoch 563/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0217 - mean_squared_error: 0.0217\n",
            "Epoch 564/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
            "Epoch 565/1000\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0214 - mean_squared_error: 0.0214\n",
            "Epoch 566/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
            "Epoch 567/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0221 - mean_squared_error: 0.0221\n",
            "Epoch 568/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
            "Epoch 569/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0212 - mean_squared_error: 0.0212\n",
            "Epoch 570/1000\n",
            "100/100 [==============================] - 0s 201us/step - loss: 0.0216 - mean_squared_error: 0.0216\n",
            "Epoch 571/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
            "Epoch 572/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
            "Epoch 573/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0213 - mean_squared_error: 0.0213\n",
            "Epoch 574/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
            "Epoch 575/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
            "Epoch 576/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0209 - mean_squared_error: 0.0209\n",
            "Epoch 577/1000\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
            "Epoch 578/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0207 - mean_squared_error: 0.0207\n",
            "Epoch 579/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0210 - mean_squared_error: 0.0210\n",
            "Epoch 580/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0210 - mean_squared_error: 0.0210\n",
            "Epoch 581/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0203 - mean_squared_error: 0.0203\n",
            "Epoch 582/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0207 - mean_squared_error: 0.0207\n",
            "Epoch 583/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0210 - mean_squared_error: 0.0210\n",
            "Epoch 584/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0216 - mean_squared_error: 0.0216\n",
            "Epoch 585/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0221 - mean_squared_error: 0.0221\n",
            "Epoch 586/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0212 - mean_squared_error: 0.0212\n",
            "Epoch 587/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
            "Epoch 588/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0210 - mean_squared_error: 0.0210\n",
            "Epoch 589/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0203 - mean_squared_error: 0.0203\n",
            "Epoch 590/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
            "Epoch 591/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0203 - mean_squared_error: 0.0203\n",
            "Epoch 592/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
            "Epoch 593/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0217 - mean_squared_error: 0.0217\n",
            "Epoch 594/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0204 - mean_squared_error: 0.0204\n",
            "Epoch 595/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0201 - mean_squared_error: 0.0201\n",
            "Epoch 596/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0212 - mean_squared_error: 0.0212\n",
            "Epoch 597/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
            "Epoch 598/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0220 - mean_squared_error: 0.0220\n",
            "Epoch 599/1000\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.0193 - mean_squared_error: 0.0193\n",
            "Epoch 600/1000\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.0202 - mean_squared_error: 0.0202\n",
            "Epoch 601/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0206 - mean_squared_error: 0.0206\n",
            "Epoch 602/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0198 - mean_squared_error: 0.0198\n",
            "Epoch 603/1000\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
            "Epoch 604/1000\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0196 - mean_squared_error: 0.0196\n",
            "Epoch 605/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0190 - mean_squared_error: 0.0190\n",
            "Epoch 606/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0197 - mean_squared_error: 0.0197\n",
            "Epoch 607/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0194 - mean_squared_error: 0.0194\n",
            "Epoch 608/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0193 - mean_squared_error: 0.0193\n",
            "Epoch 609/1000\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.0200 - mean_squared_error: 0.0200\n",
            "Epoch 610/1000\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.0199 - mean_squared_error: 0.0199\n",
            "Epoch 611/1000\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.0192 - mean_squared_error: 0.0192\n",
            "Epoch 612/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0195 - mean_squared_error: 0.0195\n",
            "Epoch 613/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0190 - mean_squared_error: 0.0190\n",
            "Epoch 614/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0187 - mean_squared_error: 0.0187\n",
            "Epoch 615/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
            "Epoch 616/1000\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.0192 - mean_squared_error: 0.0192\n",
            "Epoch 617/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0189 - mean_squared_error: 0.0189\n",
            "Epoch 618/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0185 - mean_squared_error: 0.0185\n",
            "Epoch 619/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0191 - mean_squared_error: 0.0191\n",
            "Epoch 620/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
            "Epoch 621/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
            "Epoch 622/1000\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.0189 - mean_squared_error: 0.0189\n",
            "Epoch 623/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
            "Epoch 624/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0193 - mean_squared_error: 0.0193\n",
            "Epoch 625/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
            "Epoch 626/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
            "Epoch 627/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
            "Epoch 628/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0182 - mean_squared_error: 0.0182\n",
            "Epoch 629/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
            "Epoch 630/1000\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.0181 - mean_squared_error: 0.0181\n",
            "Epoch 631/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
            "Epoch 632/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
            "Epoch 633/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0187 - mean_squared_error: 0.0187\n",
            "Epoch 634/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
            "Epoch 635/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0182 - mean_squared_error: 0.0182\n",
            "Epoch 636/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0178 - mean_squared_error: 0.0178\n",
            "Epoch 637/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 638/1000\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0181 - mean_squared_error: 0.0181\n",
            "Epoch 639/1000\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.0181 - mean_squared_error: 0.0181\n",
            "Epoch 640/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0178 - mean_squared_error: 0.0178\n",
            "Epoch 641/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
            "Epoch 642/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
            "Epoch 643/1000\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
            "Epoch 644/1000\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
            "Epoch 645/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
            "Epoch 646/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0171 - mean_squared_error: 0.0171\n",
            "Epoch 647/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 648/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0176 - mean_squared_error: 0.0176\n",
            "Epoch 649/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
            "Epoch 650/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
            "Epoch 651/1000\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 652/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0172 - mean_squared_error: 0.0172\n",
            "Epoch 653/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
            "Epoch 654/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
            "Epoch 655/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0170 - mean_squared_error: 0.0170\n",
            "Epoch 656/1000\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 657/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0172 - mean_squared_error: 0.0172\n",
            "Epoch 658/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
            "Epoch 659/1000\n",
            "100/100 [==============================] - 0s 195us/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 660/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0171 - mean_squared_error: 0.0171\n",
            "Epoch 661/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0167 - mean_squared_error: 0.0167\n",
            "Epoch 662/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 663/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
            "Epoch 664/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0164 - mean_squared_error: 0.0164\n",
            "Epoch 665/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0171 - mean_squared_error: 0.0171\n",
            "Epoch 666/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0185 - mean_squared_error: 0.0185\n",
            "Epoch 667/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0175 - mean_squared_error: 0.0175\n",
            "Epoch 668/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0175 - mean_squared_error: 0.0175\n",
            "Epoch 669/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.0175 - mean_squared_error: 0.0175\n",
            "Epoch 670/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0168 - mean_squared_error: 0.0168\n",
            "Epoch 671/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
            "Epoch 672/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 673/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0164 - mean_squared_error: 0.0164\n",
            "Epoch 674/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
            "Epoch 675/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
            "Epoch 676/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 677/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
            "Epoch 678/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 679/1000\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 680/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0167 - mean_squared_error: 0.0167\n",
            "Epoch 681/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
            "Epoch 682/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
            "Epoch 683/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
            "Epoch 684/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 685/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
            "Epoch 686/1000\n",
            "100/100 [==============================] - 0s 202us/step - loss: 0.0164 - mean_squared_error: 0.0164\n",
            "Epoch 687/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0157 - mean_squared_error: 0.0157\n",
            "Epoch 688/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0167 - mean_squared_error: 0.0167\n",
            "Epoch 689/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 690/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 691/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 692/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 693/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 694/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
            "Epoch 695/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 696/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 697/1000\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 698/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 699/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 700/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0157 - mean_squared_error: 0.0157\n",
            "Epoch 701/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 702/1000\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 703/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 704/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 705/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 706/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 707/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 708/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 709/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 710/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 711/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 712/1000\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 713/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 714/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 715/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
            "Epoch 716/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 717/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 718/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 719/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 720/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 721/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
            "Epoch 722/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
            "Epoch 723/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 724/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
            "Epoch 725/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 726/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 727/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 728/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 729/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 730/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 731/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 732/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 733/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 734/1000\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 735/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 736/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 737/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
            "Epoch 738/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 739/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 740/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
            "Epoch 741/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 742/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 743/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 744/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 745/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 746/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 747/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 748/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 749/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 750/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 751/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 752/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 753/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 754/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 755/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 756/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 757/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 758/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
            "Epoch 759/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 760/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 761/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 762/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 763/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 764/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 765/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 766/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 767/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 768/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 769/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 770/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 771/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 772/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 773/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 774/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 775/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 776/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 777/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 778/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 779/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 780/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 781/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 782/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 783/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 784/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 785/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 786/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 787/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 788/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 789/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 790/1000\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 791/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 792/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 793/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 794/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 795/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 796/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 797/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 798/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 799/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 800/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 801/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 802/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 803/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 804/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 805/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 806/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 807/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 808/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 809/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 810/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 811/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 812/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 813/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 814/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 815/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 816/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 817/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 818/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 819/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 820/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 821/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 822/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 823/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 824/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 825/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 826/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 827/1000\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 828/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 829/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 830/1000\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 831/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 832/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 833/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 834/1000\n",
            "100/100 [==============================] - 0s 198us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 835/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 836/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 837/1000\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 838/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 839/1000\n",
            "100/100 [==============================] - 0s 200us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 840/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 841/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 842/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 843/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 844/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 845/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 846/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 847/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 848/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 849/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 850/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 851/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 852/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 853/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 854/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 855/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 856/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 857/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 858/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 859/1000\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 860/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 861/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 862/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 863/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 864/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 865/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 866/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 867/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 868/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 869/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 870/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 871/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 872/1000\n",
            "100/100 [==============================] - 0s 204us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 873/1000\n",
            "100/100 [==============================] - 0s 202us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 874/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 875/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 876/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 877/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 878/1000\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 879/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 880/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 881/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 882/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 883/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 884/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 885/1000\n",
            "100/100 [==============================] - 0s 194us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 886/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 887/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 888/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 889/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 890/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 891/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 892/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 893/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 894/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 895/1000\n",
            "100/100 [==============================] - 0s 218us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 896/1000\n",
            "100/100 [==============================] - 0s 203us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 897/1000\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 898/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 899/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 900/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 901/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 902/1000\n",
            "100/100 [==============================] - 0s 199us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 903/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 904/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 905/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 906/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 907/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 908/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 909/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 910/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 911/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 912/1000\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 913/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 914/1000\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 915/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 916/1000\n",
            "100/100 [==============================] - 0s 207us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 917/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 918/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 919/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 920/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 921/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 922/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 923/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 924/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 925/1000\n",
            "100/100 [==============================] - 0s 210us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 926/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 927/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 928/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 929/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 930/1000\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 931/1000\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 932/1000\n",
            "100/100 [==============================] - 0s 209us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 933/1000\n",
            "100/100 [==============================] - 0s 206us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 934/1000\n",
            "100/100 [==============================] - 0s 205us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 935/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 936/1000\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 937/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 938/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 939/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 940/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 941/1000\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 942/1000\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
            "Epoch 943/1000\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 944/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 945/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 946/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 947/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 948/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 949/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 950/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 951/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 952/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 953/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 954/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 955/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 956/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 957/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 958/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 959/1000\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 960/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 961/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 962/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 963/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 964/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 965/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 966/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 967/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 968/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 969/1000\n",
            "100/100 [==============================] - 0s 227us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 970/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 971/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 972/1000\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 973/1000\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 974/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 975/1000\n",
            "100/100 [==============================] - 0s 211us/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 976/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 977/1000\n",
            "100/100 [==============================] - 0s 224us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 978/1000\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 979/1000\n",
            "100/100 [==============================] - 0s 225us/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 980/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 981/1000\n",
            "100/100 [==============================] - 0s 238us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 982/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 983/1000\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 984/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 985/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 986/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 987/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 988/1000\n",
            "100/100 [==============================] - 0s 219us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 989/1000\n",
            "100/100 [==============================] - 0s 223us/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 990/1000\n",
            "100/100 [==============================] - 0s 215us/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 991/1000\n",
            "100/100 [==============================] - 0s 217us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 992/1000\n",
            "100/100 [==============================] - 0s 216us/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 993/1000\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 994/1000\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 995/1000\n",
            "100/100 [==============================] - 0s 221us/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 996/1000\n",
            "100/100 [==============================] - 0s 213us/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 997/1000\n",
            "100/100 [==============================] - 0s 212us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 998/1000\n",
            "100/100 [==============================] - 0s 208us/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 999/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 1000/1000\n",
            "100/100 [==============================] - 0s 214us/step - loss: 0.0122 - mean_squared_error: 0.0122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43f59542d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "wgzPrQkA1uUP",
        "colab_type": "code",
        "outputId": "9dda9289-9770-45f1-ffeb-7af03a7cb14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(20,5))\n",
        "\n",
        "p = plt.subplot(1,2,1)\n",
        "x_np = np.linspace(0, 1, 500)\n",
        "# y_np = []\n",
        "# print(model.predict(x_np))\n",
        "y_np = model.predict(x_np)\n",
        "\n",
        "\n",
        "p.plot(x_np, np.sin(2*np.pi*x_np), \"b\")\n",
        "p.plot(x_np, y_np, 'r--')\n",
        "p.plot(x_vals, y_vals, 'go')\n",
        "p.set_xlabel('x')\n",
        "p.set_ylabel('y')\n",
        "p.set_title('Fit 1')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAFMCAYAAADRDFZ1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOv/PYEcQMdlpLEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f43f56fce50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}